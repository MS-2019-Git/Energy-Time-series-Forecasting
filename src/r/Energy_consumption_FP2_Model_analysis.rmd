---
title: "FP_Model"
author: "Gurjit"
date: "25/01/2022"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA)
```

```{r include="FALSE", warning = FALSE}




library(openxlsx);       
library(ggplot2)
library(forecast);
library(DataExplorer);   
library("ggpubr")
library(tseries)

```

## Read the given Jewelry Value Dataset

```{r warning=FALSE}

setwd("C:/Term5/FP")
getwd()

energy_data <- read.xlsx('energy_data.xlsx')

#energy_data <- read.csv("state_energy_all_states.csv")

#energy_data$Date<-as.Date(format(energy_data$Date*100+1),"%Y%m%d")


# Convert data type of Date column
energy_data$Date <- as.Date(energy_data$Date)

summary(energy_data)
str(energy_data)



```


### EDA: Basic Structure of Data


```{r}
str(energy_data)
```

- Deduction:
- The basic structure of dataset shows that energy_dataset consists of 2 columns:
  - Date, Date
  - Value, numeric
  

### EDA: Check for Missing Data

#### The number of rows having missing data is: 

```{r}
row.has.na <- apply(energy_data, 1, function(x){any(is.na(x))})
sum(row.has.na)
```

### **Plot of missing records**

```{r  echo=FALSE}
plot_missing(energy_data)
```

**Note:** The above plot shows that None of the columns have missing data.




### EDA: Correlation Analysis

```{r}

hist(energy_data$Value)


```

```{r }
# Visualizing overall Time Series

energy_data %>% 
  ggplot(aes(x = `Date`, y = Value)) +
  geom_line(color = "blue") + geom_point() +
  geom_smooth(method='lm', formula= y~x)



```


**From above we can see yearly seasonality , so we decompose data into Monthly **

# Convert data to timeseries

```{r }
Value.data <- ts(energy_data$Value,start=c(2001, 1), frequency=12)


```




=====================================================================

### (a) Plot the time series of the original data. Which time series components appear from the plot.

=====================================================================


```{r }

ssA <- decompose(Value.data, type= "additive")
g1 <- autoplot(ssA)
ssM <- decompose(Value.data, type= "multiplicative")
g2 <- autoplot(ssM)

ggarrange(g1,g2)
```






**Seasonal Plot**

```{r }

autoplot(Value.data) +   ylab("Energy Value") + xlab("Timeline") + ggtitle("Value Chart") + theme(plot.title = element_text(hjust = 0.5))

# Souvenir Sales Seasonal Plot
ggseasonplot(Value.data, year.labels=TRUE, year.labels.left=TRUE) + ylab("Units Value") +
ggtitle("Energy Value  plot") + theme(plot.title = element_text(hjust = 0.5))

```





### Identifying components from Graph

- A Time Series data consists of a Trend and Seasonality  Component, which are quite visible from the above trend & other plots above.
- Other than Trend and Seasonality  Component, there are residuals which can be seen from decomposition plot and needs to be analysed further.
- The graph shows a linear trend with time and reflects growth in Value with each year.
- There is a repetitive pattern in Value variation across years, and seasonal variations increase proportionally with time.  
- We can see there is drop in Value during the month of may/June every year. 


**split data into Training & Validation**

```{r }





train_data <- window(Value.data,end=c(2020,12), frequency=12)
test_data <- window(Value.data,start=c(2021,1), frequency=12)



```

=====================================================================

.

=====================================================================




**Model_A - Linear trend model with additive seasonality**

```{r }


energy.additive <- tslm(train_data ~ trend  +  season)



## Forecasting on the validation test


energy.additive.pred <- forecast(energy.additive , h=length(test_data), level = 95) 


```




**Model_B -  Exponential trend model with multiplicative seasonality **

```{r }



## Building multiplicative Trend Model
energy.multiplicative <- tslm(train_data ~ trend +  season , lambda = 0 )  




## Forecasting on the validation test
energy.multiplicative.pred <- forecast(energy.multiplicative , h=length(test_data), level = 95) 



```




=====================================================================



=====================================================================

**Comparison of RMSE**

```{r }

## Accuracy of the model A

print("Accuracy of Additive model")

accuracy(energy.additive.pred$mean,test_data)



print("Accuracy of Multiplicative model")

## Accuracy of the model B

accuracy(energy.multiplicative.pred$mean,test_data)




```



## Comparing linear vs exponential trend

```{r }

plot(train_data, xlab ="Time", ylab= "Souvenir Value", main="linear vs exponential trend Model", bty="l", ylim=c(0,90000))
lines(energy.multiplicative.pred$fitted, col="blue", lwd=2)
lines(energy.additive.pred$fitted, col="red", lwd=2)
legend(2001,70000, legend=c("Linear", "Exponential"),  col=c("red", "blue"), lty=1:1, cex=1)

```



**Additive Model:**

============================





***- R-Square is XX, which means XX of variation in Value in explained by the Model***






**Plots from Additive model**

```{r }
## Plot actual & Forecasted 

plot(energy.additive.pred, xlab ="Time", ylab= "Units consumed ", main="Energy Value Value ", ylim= c(0,110000))
lines(energy.additive.pred$fitted,col="red",lwd=2, lty=1)
lines(test_data)
legend(2001,85000, legend=c("Original", "Forecast", "Fitted"),  col=c("black", "blue","red"), lty=1:1, cex=1)



## Plot residuals 



plot(energy.additive$residuals,type="o", xlim= c(2001,2012), ylim= c(-25000,45000),main= "Residual Plot-Model A", ylab="Forecast Error",lwd=2)
lines(test_data-energy.additive.pred$mean, col="blue",lwd=2,type="o")
abline(v=2001, col="red", lwd=2)
abline(0,0,col="black",lwd=0.5)
text(2001,30000, "Training ")
text(2001.5,35000, "Validation")



```


=====================================================================

### f) Preparing final model & forecasting for year 2022.

=====================================================================



**Step 1- Estimating coefficients****
.

```{r }


energy.final.model <- tslm(Value.data ~ trend +  season )  

energy.final.model 


summary(energy.final.model)




```

**Step 2- Forecasting 1- year, starting from  Oct 2021 **

```{r }

## Forecasting on the validation test
energy.final.model.pred <- forecast(energy.final.model , h= 12, level = 95) 


energy.final.model.pred




```


**Forecasted Value for the month of January 2002 is 13484.06**



=====================================================================

### (g) Plot the ACF and PACF plot until lag 20 of the residuals obtained from training set of the best model chosen. Comment on these plots and think what AR(p) model could be a good choice?


=====================================================================

```{r }

Acf(energy.additive$residuals,lag.max = 20)



Pacf(energy.additive$residuals,lag.max = 20)


AIC(energy.additive,energy.multiplicative)

```

**Looking at the data above, we can say that their is some positive Auto correlation which exists between the observations and its recent past for first two time period lags( This is visible from bars outside blue significance line). However, the correlation doesn't exists as lag increases.***

**- The bars in ACF plot are going  down very fast ,So we can say that trend and seasonality have been removed**

**- Further we will remove auto-correlations using AR(p) model, where Value of p is 2 , as observed from ACF plot above**

**- there exist any stickiness, however few swings can be seen in the ACF plot**




=====================================================================


=====================================================================


## check if data is stationary after removing trend and seasonality

**We used kpss test for the same. If p-Value >0.05 . We  Fail to Reject null hypothesis ,so we conclude that data is stationary **

```{r }


kpss.test(energy.additive$residuals)

```

**Fitting an AR Model- considering Auto-correlation for first two periods**

**Building ACF & PACF plot- using residuals from AR model **

```{r }

error_arima =energy.additive$residuals



train_arima <- Arima(error_arima, order = c(12,0,0))
summary(train_arima)

Acf(train_arima$residuals, lag.max=20)


Pacf(train_arima$residual,lag.max = 20)


```





=====================================================================


### 

=====================================================================



**- Forecasting error from residuals**

```{r }

error_arima_final = energy.final.model$residuals

Acf(error_arima_final, lag.max=20)


Pacf(error_arima_final,lag.max = 20)




train_arima_final <- Arima(error_arima_final, order = c(2,0,0))

Acf(train_arima_final$residuals, lag.max=20)


Pacf(train_arima_final$residuals,lag.max = 20)


summary(train_arima_final)






train_arima_final.pred <- forecast(train_arima_final,h=1)

train_arima_final.pred


```


**Revised error forecast = 17000.06**

**Predicted Value from AR(p) model = Predicted Value from Final model + Predicted Error.**



```{r }



auto_fit <- auto.arima(train_data)

summary(auto_fit)




## Forecasting on the validation test
auto_fit.pred <- forecast(auto_fit  , h=length(test_data), level = 95) 


## Accuracy of the Auto model 

print("Accuracy of Auto Arima model")

accuracy(auto_fit.pred$mean,test_data)




plot(forecast(auto_fit,h=12))

checkresiduals(auto_fit)




```
```{r }

AIC(energy.additive,auto_fit )
BIC(energy.additive,auto_fit )


```
**RMSE & AiC is least for auto Fit arima model model** 

```{r }
auto_fit.pred

```
**Preparing and prediciting from final arima model** 

```{r }
auto_final <- auto.arima(Value.data)

summary(auto_final)




## Forecasting on the validation test
auto_final.pred <- forecast(auto_final  , h=6, level = 95) 


checkresiduals(auto_final)


auto_final.pred

```

